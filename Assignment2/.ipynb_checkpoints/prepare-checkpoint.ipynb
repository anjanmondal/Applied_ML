{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e98665-bc11-4ed6-97f2-daf4952d63a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /home/kashyap/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1496cd83-6983-477d-a205-2bfd2b114317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in G:/Coursework/AML/Assignment/A2/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b85d46dd-7f5d-4415-b1ad-6d65ae325f37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "+---------------------------------------------------------------------+\n",
      "|                                                                     |\n",
      "|        DVC has enabled anonymous aggregate usage analytics.         |\n",
      "|     Read the analytics documentation (and how to opt-out) here:     |\n",
      "|             <https://dvc.org/doc/user-guide/analytics>              |\n",
      "|                                                                     |\n",
      "+---------------------------------------------------------------------+\n",
      "\n",
      "What's next?\n",
      "------------\n",
      "- Check out the documentation: <https://dvc.org/doc>\n",
      "- Get help and share ideas: <https://dvc.org/chat>\n",
      "- Star us on GitHub: <https://github.com/iterative/dvc>\n"
     ]
    }
   ],
   "source": [
    "!dvc init -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbd5ce93-1876-4c0e-a824-441c518581cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dvc config core.autostage true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6938e04-1b6f-4d7a-93b5-506ebadddc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git rm --cached <file>...\" to unstage)\n",
      "\tnew file:   .dvc/.gitignore\n",
      "\tnew file:   .dvc/config\n",
      "\tnew file:   .dvcignore\n",
      "\tnew file:   .gitignore\n",
      "\tnew file:   test.csv.dvc\n",
      "\tnew file:   train.csv.dvc\n",
      "\tnew file:   validation.csv.dvc\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   .dvc/config\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/\n",
      "\temails.csv\n",
      "\tprepare.ipynb\n",
      "\ttrain.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2e6abce-46e6-490d-a798-52179b9038ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "def preprocess_data(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "   \n",
    "    data['text'] = data['text'].apply(lambda x: x.lower())      # Convert text to lowercase\n",
    "    data['text'] = data['text'].apply(word_tokenize)   # Tokenize the text\n",
    "    data['text'] = data['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    data['text'] = data['text'].apply(lambda x: ' '.join(x)) # Join the tokens back into a single string\n",
    "    data['text'] = data['text'].str.replace('[^\\w\\s]', '', regex = True)# Remove punctuation\n",
    "    data['text'] = data['text'].str.replace('\\d+', '', regex = True) # Remove numbers\n",
    "    return data\n",
    "\n",
    "def split_data(data, seed =42):\n",
    "    X = data['text']\n",
    "    y = data['spam']\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=seed, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "    train_data = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "    val_data = pd.DataFrame({'text': X_val, 'label': y_val})\n",
    "    test_data = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def store_data(train_data, val_data, test_data):\n",
    "    train_data.to_csv('train.csv', index=False)\n",
    "    val_data.to_csv('validation.csv', index=False)\n",
    "    test_data.to_csv('test.csv', index=False)\n",
    "\n",
    "# Load data\n",
    "data = load_data('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a72ec36e-d1a3-46c8-b401-14c4967029f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9103329f-2ea7-4f4e-9624-7aad34f50554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.238827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.426404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              spam\n",
       "count  5728.000000\n",
       "mean      0.238827\n",
       "std       0.426404\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02ea0696-a910-4fdb-97bb-0862d353ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5728 entries, 0 to 5727\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5728 non-null   object\n",
      " 1   spam    5728 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 89.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bd7c03d-802f-4b76-877c-8665e0f55ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text\n",
       "spam      \n",
       "0     4360\n",
       "1     1368"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"spam\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8c5c97a-72e4-4104-944d-05ec47ad3033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.countplot(x='spam',data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "03265adf-51d2-488b-98f7-005801aac4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f630293-b615-4c2a-840d-c96222d64cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subject  naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject  the stock trading gunslinger fanny is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subject  unbelievable new home made easy im wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subject   color printing special request addit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subject  do not have money  get software cd fr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>subject  re  research and development charge t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>subject  re  receipt from visit jim  thanks ag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>subject  re  enron case study update wow  all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>subject  re  interest david  please  call shir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>subject  news  aurora    update aurora version...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     subject  naturally irresistible your corporate...     1\n",
       "1     subject  the stock trading gunslinger fanny is...     1\n",
       "2     subject  unbelievable new home made easy im wa...     1\n",
       "3     subject   color printing special request addit...     1\n",
       "4     subject  do not have money  get software cd fr...     1\n",
       "...                                                 ...   ...\n",
       "5723  subject  re  research and development charge t...     0\n",
       "5724  subject  re  receipt from visit jim  thanks ag...     0\n",
       "5725  subject  re  enron case study update wow  all ...     0\n",
       "5726  subject  re  interest david  please  call shir...     0\n",
       "5727  subject  news  aurora    update aurora version...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "007fe13d-ffa3-4dce-89be-074e85bd2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = split_data(data, seed = 42)\n",
    "\n",
    "store_data(train_data, val_data, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e22095ee-07e2-4ad8-8a13-2bf1f2133cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u280b Checking graph\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!dvc add train.csv validation.csv test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b6ab908-e6df-46bd-aa05-05f91137967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add train.csv.dvc validation.csv.dvc test.csv.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfd19f4f-abcb-4c8b-8148-027e9d9469be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git rm --cached <file>...\" to unstage)\n",
      "\tnew file:   .dvc/.gitignore\n",
      "\tnew file:   .dvc/config\n",
      "\tnew file:   .dvcignore\n",
      "\tnew file:   .gitignore\n",
      "\tnew file:   test.csv.dvc\n",
      "\tnew file:   train.csv.dvc\n",
      "\tnew file:   validation.csv.dvc\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   .dvc/config\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/\n",
      "\temails.csv\n",
      "\tprepare.ipynb\n",
      "\ttrain.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!git status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d7a0ad3-439b-41d8-849f-09fb7eed0975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: pathspec 'version' did not match any file(s) known to git\n",
      "error: pathspec 'of' did not match any file(s) known to git\n",
      "error: pathspec 'data' did not match any file(s) known to git\n",
      "error: pathspec 'created'' did not match any file(s) known to git\n"
     ]
    }
   ],
   "source": [
    "!git commit -m 'First version of data created'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d599d61-c07b-49ef-bdf3-ae76044d4214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessed_text</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new computers hi lyn hope things going better ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contstraints shape smile stinson vince zimin b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tropical cyclones dear yesterday mentioned vin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>university texas conference energy finance feb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sokolov eis expenses hi kevin office thursday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>anticipated assistant required mr ike ejoh ban...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>houston research opportunity dear vince would ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>frank thanks given name employee energy power ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>monte carlo techniques zimin course descriptio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>conference volume hi vince resending request d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4009 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Preprocessed_text  Spam\n",
       "0     new computers hi lyn hope things going better ...     0\n",
       "1     contstraints shape smile stinson vince zimin b...     0\n",
       "2     tropical cyclones dear yesterday mentioned vin...     0\n",
       "3     university texas conference energy finance feb...     0\n",
       "4     sokolov eis expenses hi kevin office thursday ...     0\n",
       "...                                                 ...   ...\n",
       "4004  anticipated assistant required mr ike ejoh ban...     1\n",
       "4005  houston research opportunity dear vince would ...     0\n",
       "4006  frank thanks given name employee energy power ...     0\n",
       "4007  monte carlo techniques zimin course descriptio...     0\n",
       "4008  conference volume hi vince resending request d...     0\n",
       "\n",
       "[4009 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb6169dc-5878-4252-82f1-5ffad287786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test_valid, y_train, y_test_valid = train_test_split(data['after_token'], data['spam'], stratify = data['spam'], train_size = 0.7, random_state = 752)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test_valid, y_test_valid, stratify = y_test_valid, train_size = 0.5, random_state = 456)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6ae9175-92b7-4382-89d4-74f141e49724",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop = True)\n",
    "X_valid = X_valid.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "y_valid = y_valid.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63c2fc1c-d4e2-42c6-904d-c94c9c8f7c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame()\n",
    "train_dataset['Preprocessed_text'] = X_train\n",
    "train_dataset['Spam'] = y_train\n",
    "\n",
    "test_dataset = pd.DataFrame()\n",
    "test_dataset['Preprocessed_text'] = X_test\n",
    "test_dataset['Spam'] = y_test\n",
    "\n",
    "valid_dataset = pd.DataFrame()\n",
    "valid_dataset['Preprocessed_text'] = X_valid\n",
    "valid_dataset['Spam'] = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c891f686-688b-4163-a790-4206db5bc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.to_csv('train.csv', index = False)\n",
    "test_dataset.to_csv('test.csv', index = False)\n",
    "valid_dataset.to_csv('validation.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ac98d51-61e1-491e-b0f6-de352fd20858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "  0% Adding...|                          | train.csv |0/3 [00:00<?,     ?file/s]\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in train.csv    |0.00 [00:00,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/kashyap/AML Assignments/AML_Assignment2/.dvc/cache\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/kashyap/AML Assignm0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "  0% Adding...|                     | validation.csv |0/3 [00:00<?,     ?file/s]\u001b[A\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in validation.csv |0.00 [00:00,     ?file/\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/kashyap/AML Assignments/AML_Assignment2/.dvc/cache\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/kashyap/AML Assignm0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "  0% Adding...|                           | test.csv |0/3 [00:00<?,     ?file/s]\u001b[A\n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in test.csv     |0.00 [00:00,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/kashyap/AML Assignments/AML_Assignment2/.dvc/cache\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/kashyap/AML Assignm0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|3/3 [00:00, 40.69file/s]\u001b[A\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add train.csv validation.csv test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2c7646d-57e5-4f48-b5b9-67a104e55d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add train.csv.dvc validation.csv.dvc test.csv.dvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "961cf03d-4dcb-48b8-ab64-ef0d0c72b8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 9d1af8e] Updated version of data created\n",
      " 3 files changed, 6 insertions(+), 6 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git commit -m 'Updated version of data created'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30276d3a-866e-42aa-9e5b-ec06cf75d8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preprocessed_text</th>\n",
       "      <th>Spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>analyst candidate mitra mujica mitra mujica ac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>approval overdue access request paul thomas en...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>giuseppe cell phone stinson problem vince stin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000 expenses know deadline 2000 invoices ap f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>houston trip extended rental apartment 20 th n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004</th>\n",
       "      <td>howard lawrence vince hey vince picture howard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>custom logos identities us thinking breathing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>reactions september live line reactions latest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>vince kaminski discussion notes enterprise wid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>chheep medz save vacationist n medlcations 70 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4009 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Preprocessed_text  Spam\n",
       "0     analyst candidate mitra mujica mitra mujica ac...     0\n",
       "1     approval overdue access request paul thomas en...     0\n",
       "2     giuseppe cell phone stinson problem vince stin...     0\n",
       "3     2000 expenses know deadline 2000 invoices ap f...     0\n",
       "4     houston trip extended rental apartment 20 th n...     0\n",
       "...                                                 ...   ...\n",
       "4004  howard lawrence vince hey vince picture howard...     0\n",
       "4005  custom logos identities us thinking breathing ...     1\n",
       "4006  reactions september live line reactions latest...     0\n",
       "4007  vince kaminski discussion notes enterprise wid...     0\n",
       "4008  chheep medz save vacationist n medlcations 70 ...     1\n",
       "\n",
       "[4009 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69c56725-c56a-442e-b6a6-d867882cf9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mcommit 9d1af8eb27cfbfa01769587b63ac35a4cde7a7e2\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m -> \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m)\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sun Feb 18 00:13:21 2024 +0530\n",
      "\n",
      "    Updated version of data created\n",
      "\n",
      "\u001b[33mcommit 3371fa0f5e75fc52b0a367f086acf8167fec148c\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sun Feb 18 00:12:17 2024 +0530\n",
      "\n",
      "    First version of data created\n",
      "\n",
      "\u001b[33mcommit de796d9e223155308696c92dee77b55e9aa0c13b\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sun Feb 18 00:03:21 2024 +0530\n",
      "\n",
      "    2nd batch of data created\n",
      "\n",
      "\u001b[33mcommit bb5bc6db89039088dc17ad5c83d786c609ed71b4\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sun Feb 18 00:01:10 2024 +0530\n",
      "\n",
      "    1st batch of data created\n",
      "\n",
      "\u001b[33mcommit 1982aeef82f2a6bf0c19c77ad36bfa98a15ffe5e\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sat Feb 17 23:46:01 2024 +0530\n",
      "\n",
      "    fixing error\n",
      "\n",
      "\u001b[33mcommit cbb332d068c97ee86158eb0c9ce0399b78a94c15\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sat Feb 17 23:41:19 2024 +0530\n",
      "\n",
      "    trail\n",
      "\n",
      "\u001b[33mcommit 5b690a2addd1a42a0cc26933fcce46499f81216e\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sat Feb 17 23:28:36 2024 +0530\n",
      "\n",
      "    dvc init\n",
      "\n",
      "\u001b[33mcommit 11968e6e5bc7518dbeca85bcca41958bcd1d030a\u001b[m\u001b[33m (\u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m)\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sat Feb 17 21:30:39 2024 +0530\n",
      "\n",
      "    trail\n",
      "\n",
      "\u001b[33mcommit 12749e5a6c9efc2f3b940cb30c42f878d4274edf\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sat Feb 17 21:10:33 2024 +0530\n",
      "\n",
      "    Added prepare.ipynb notebook and tried dvc for train.csv, test.csv and validation.csv\n",
      "\n",
      "\u001b[33mcommit bed166896e968caef88598c0485f0c8f050e1ad4\u001b[m\n",
      "Author: anurajkashyap <anurajkashyap1234@gmail.com>\n",
      "Date:   Sat Feb 17 19:47:36 2024 +0530\n",
      "\n",
      "    Added emails.csv dataset\n"
     ]
    }
   ],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5544ba3f-cfd1-4179-9c9a-178c0fd27479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\tprepare.ipynb\n",
      "Note: switching to '3371fa0f5e75fc52b0a367f086acf8167fec148c'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 3371fa0 First version of data created\n"
     ]
    }
   ],
   "source": [
    "!git checkout 3371fa0f5e75fc52b0a367f086acf8167fec148c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "452018b7-61a0-4922-93f6-3b5f7003ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building workspace index                              |3.00 [00:00, 73.9entry/s]\n",
      "Comparing indexes                                    |4.00 [00:00, 1.49kentry/s]\n",
      "Applying changes                                      |3.00 [00:00,   119file/s]\n",
      "\u001b[33mM\u001b[0m       validation.csv\n",
      "\u001b[33mM\u001b[0m       test.csv\n",
      "\u001b[33mM\u001b[0m       train.csv\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa0a1d25-5253-4fa9-92ea-165146dc0d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target variable in train.csv (before update):\n",
      "Spam\n",
      "0    3052\n",
      "1     957\n",
      "Name: count, dtype: int64\n",
      "Distribution of target variable in validation.csv (before update):\n",
      "Spam\n",
      "0    654\n",
      "1    206\n",
      "Name: count, dtype: int64\n",
      "Distribution of target variable in test.csv (before update):\n",
      "Spam\n",
      "0    654\n",
      "1    205\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of target variable in train.csv (before update):\")\n",
    "train_data = pd.read_csv('train.csv')\n",
    "print(train_data['Spam'].value_counts())\n",
    "print(\"Distribution of target variable in validation.csv (before update):\")\n",
    "validation_data = pd.read_csv('validation.csv')\n",
    "print(validation_data['Spam'].value_counts())\n",
    "print(\"Distribution of target variable in test.csv (before update):\")\n",
    "test_data = pd.read_csv('test.csv')\n",
    "print(test_data['Spam'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a59104f3-b5b3-4a69-841c-c6ec4a6d07bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\tprepare.ipynb\n",
      "Note: switching to '9d1af8eb27cfbfa01769587b63ac35a4cde7a7e2'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 9d1af8e Updated version of data created\n"
     ]
    }
   ],
   "source": [
    "!git checkout 9d1af8eb27cfbfa01769587b63ac35a4cde7a7e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "269ba94f-181d-49cb-9763-cfbdfd62885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building workspace index                              |3.00 [00:00,  157entry/s]\n",
      "Comparing indexes                                    |4.00 [00:00, 3.93kentry/s]\n",
      "Applying changes                                      |3.00 [00:00,   200file/s]\n",
      "\u001b[33mM\u001b[0m       train.csv\n",
      "\u001b[33mM\u001b[0m       validation.csv\n",
      "\u001b[33mM\u001b[0m       test.csv\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a205f33-1320-4bce-b20c-fd939853dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of target variable in train.csv (after update):\n",
      "Spam\n",
      "0    3052\n",
      "1     957\n",
      "Name: count, dtype: int64\n",
      "Distribution of target variable in validation.csv (after update):\n",
      "Spam\n",
      "0    654\n",
      "1    206\n",
      "Name: count, dtype: int64\n",
      "Distribution of target variable in test.csv (after update):\n",
      "Spam\n",
      "0    654\n",
      "1    205\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of target variable in train.csv (after update):\")\n",
    "train_data = pd.read_csv('train.csv')\n",
    "print(train_data['Spam'].value_counts())\n",
    "print(\"Distribution of target variable in validation.csv (after update):\")\n",
    "validation_data = pd.read_csv('validation.csv')\n",
    "print(validation_data['Spam'].value_counts())\n",
    "print(\"Distribution of target variable in test.csv (after update):\")\n",
    "test_data = pd.read_csv('test.csv')\n",
    "print(test_data['Spam'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
