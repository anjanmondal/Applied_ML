{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cace7ac-969b-4084-965a-47f02917b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "val = pd.read_csv('validation.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "# Separating into text and label\n",
    "X_train = train['text']\n",
    "y_train = train['label']\n",
    "X_val = val['text']\n",
    "y_val = val['label']\n",
    "X_test = test['text']\n",
    "y_test = test['label']\n",
    "\n",
    "\n",
    "label_mapping = {'Spam': 1, 'Ham': 0}\n",
    "y_train = y_train.replace(label_mapping)\n",
    "y_val = y_val.replace(label_mapping)\n",
    "y_test = y_test.replace(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc15bc8a-70e4-44c7-b4fc-695f2cea946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, average_precision_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f36c345-9405-4de4-ba01-e802dfc02e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model(model_type, X_train, y_train, X_val, y_val, hyperparams={}, metadata={}):\n",
    "    with mlflow.start_run(run_name=model_type):\n",
    "        # Define the model pipeline based on model type\n",
    "        if model_type == 'Random_Forest':\n",
    "            model_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                ('clf', RandomForestClassifier(random_state=42, **hyperparams))\n",
    "            ])\n",
    "        elif model_type == 'Bernoulli_Naive_Bayes':\n",
    "            model_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                ('clf', BernoulliNB(**hyperparams))\n",
    "            ])\n",
    "        elif model_type == 'Support_Vector_Machine':\n",
    "            model_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                ('clf', SVC(random_state=42, probability=True, **hyperparams))\n",
    "            ])\n",
    "        else:\n",
    "            raise ValueError(\"Model type not recognized.\")\n",
    "        \n",
    "        # Train the model\n",
    "        model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model on validation dataset\n",
    "        y_pred_val = model_pipeline.predict(X_val)\n",
    "        accuracy = accuracy_score(y_val, y_pred_val)\n",
    "        aucpr = average_precision_score(y_val, model_pipeline.predict_proba(X_val)[:, 1])\n",
    "\n",
    "        # Log parameters, metrics, and model\n",
    "        mlflow.log_params(hyperparams)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"aucpr\", aucpr)\n",
    "        mlflow.sklearn.log_model(model_pipeline, f\"model_{model_type}\")\n",
    "\n",
    "        # Get the run ID\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "        # Register the model in the MLflow Model Registry\n",
    "        client = MlflowClient()\n",
    "        try:\n",
    "            client.create_registered_model(model_type)\n",
    "        except Exception as e:\n",
    "            print(f\"Model {model_type} already exists in the registry.\")\n",
    "\n",
    "        # Create a new version of the model in the registry\n",
    "        model_uri = f\"runs:/{run_id}/model_{model_type}\"\n",
    "        model_version_info = client.create_model_version(model_type, model_uri, run_id)\n",
    "\n",
    "        # Add metadata tags to the model version\n",
    "        metadata['Created by'] = 'Anjan' \n",
    "        for tag_key, tag_value in metadata.items():\n",
    "            client.set_model_version_tag(\n",
    "                model_type,\n",
    "                model_version_info.version,\n",
    "                tag_key,\n",
    "                tag_value\n",
    "            )\n",
    "\n",
    "        print(f\"Model {model_type}, version {model_version_info.version} registered in the MLflow Model Registry with tags {metadata}.\")\n",
    "        print(f\"Model: {model_type}, Accuracy: {accuracy}, AUCPR: {aucpr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a108e14d-d205-4216-9a53-034dbcd74fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///G:/Coursework/AML/Assignment/A2/mlruns/607309106037128344', creation_time=1708934342659, experiment_id='607309106037128344', last_update_time=1708934342659, lifecycle_stage='active', name='Email Spam-Ham Classification', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Email Spam-Ham Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e55cfd-c6d9-4825-9026-53149dac31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\n",
    "    \"Review\": \"Passed\",\n",
    "    \"Ready for Deployment\": \"Yes\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "799839ed-53a5-4e42-bda0-4d6c0d4aaf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Miniconda\\envs\\ds\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Random_Forest, version 1 registered in the MLflow Model Registry with tags {'Created by': 'Anjan'}.\n",
      "Model: Random_Forest, Accuracy: 0.9755529685681025, AUCPR: 0.9952920386979857\n",
      "Model Bernoulli_Naive_Bayes, version 1 registered in the MLflow Model Registry with tags {'Created by': 'Anjan'}.\n",
      "Model: Bernoulli_Naive_Bayes, Accuracy: 0.9650756693830035, AUCPR: 0.995387572517552\n",
      "Model Support_Vector_Machine, version 1 registered in the MLflow Model Registry with tags {'Created by': 'Anjan'}.\n",
      "Model: Support_Vector_Machine, Accuracy: 0.989522700814901, AUCPR: 0.9988626301220084\n"
     ]
    }
   ],
   "source": [
    "# Training and logging models\n",
    "model_names = ['Random_Forest', 'Bernoulli_Naive_Bayes', 'Support_Vector_Machine']\n",
    "for model_name in model_names:\n",
    "    train_and_log_model(model_name, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe776be8-45b2-4837-9438-cb79320b79fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chosen model after comparing results stored in the user interface\n",
    "model_name = \"Support_Vector_Machine\" \n",
    "model_version = \"1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "184b07c9-b6c8-479f-b468-bc42f83d2d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "model = mlflow.sklearn.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a832c6e0-7fb5-4f8e-afcb-8e48614de387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded model to make predictions on the test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics on the test dataset\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "aucpr = average_precision_score(y_test, model.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217d38a7-abc4-43dc-854a-53a9a9c3f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset: 0.9883720930232558\n",
      "AUCPR on test dataset: 0.9983005790297361\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy on test dataset: {accuracy}\")\n",
    "print(f\"AUCPR on test dataset: {aucpr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
