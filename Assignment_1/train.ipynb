{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61b5211-75cd-42f9-8bc2-d668d111b310",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "505698b0-32c7-46a1-8968-07c5aabfbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Load data\n",
    "train_data = load_data('train.csv')\n",
    "val_data = load_data('validation.csv')\n",
    "test_data = load_data('test.csv')\n",
    "\n",
    "models = {\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        \"SVC\": SVC(kernel='sigmoid', class_weight='balanced')\n",
    "    }\n",
    "\n",
    "def fit_model(train_data = train_data, model_type='naive_bayes'):\n",
    "    # Convert text to numerical features\n",
    "    global vectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(train_data['text'])\n",
    "    \n",
    "    # Convert labels to numerical values\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(train_data['label'])\n",
    "\n",
    "\n",
    "    global models\n",
    "    # Choose the model type\n",
    "    \n",
    "    models[model_type] = models[model_type].fit(X_train,y_train)\n",
    "    \n",
    "    \n",
    "    return models[model_type], encoder\n",
    "\n",
    "def score_model(model, vectorizer, encoder, data):\n",
    "    # Convert text to numerical features\n",
    "    X = vectorizer.transform(data['text'])\n",
    "    \n",
    "    y_true = encoder.transform(data['label'])\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Print classification report\n",
    "    target_names = encoder.classes_.astype(str)  # Convert to string array\n",
    "    print(\"Classification Report:\")\n",
    "    target_names=['Ham','Spam']\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "def evaluate_model(model, vectorizer, encoder, train_data, val_data):\n",
    "    print(\"Train Data:\")\n",
    "    score_model(model, vectorizer, encoder, train_data )\n",
    "    \n",
    "    print(\"Validation Data:\")\n",
    "    score_model(model, vectorizer, encoder, val_data)\n",
    "\n",
    "\n",
    "def validate_model(train_data, val_data, model_type='naive_bayes'):\n",
    "    model, vectorizer, encoder = fit_model(train_data, model_type)\n",
    "    evaluate_model(model, vectorizer, encoder, train_data, val_data)\n",
    "    return model\n",
    "\n",
    "def score_test_models(test_data, encoder):\n",
    "\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        X_test = vectorizer.transform(test_data['text'])\n",
    "        y_test = encoder.transform(test_data['label'])\n",
    "        score_model(model, vectorizer, encoder, test_data)\n",
    "\n",
    "\n",
    "\n",
    "def score_benchmark_models(val_data, encoder):\n",
    "\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        model, encoder = fit_model(model_type = name)\n",
    "        print(model)\n",
    "        evaluate_model(model, vectorizer, encoder, train_data, val_data)\n",
    "    \n",
    "\n",
    "# Fit and evaluate models on validation data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['text'])\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(train_data['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5be9047-0bae-4c82-b13b-0227edb1bff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes:\n",
      "MultinomialNB()\n",
      "Train Data:\n",
      "Accuracy: 0.9388875031179845\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.93      1.00      0.96      3052\n",
      "        Spam       1.00      0.75      0.85       957\n",
      "\n",
      "    accuracy                           0.94      4009\n",
      "   macro avg       0.96      0.87      0.91      4009\n",
      "weighted avg       0.94      0.94      0.94      4009\n",
      "\n",
      "Validation Data:\n",
      "Accuracy: 0.9080325960419092\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.89      1.00      0.94       654\n",
      "        Spam       1.00      0.61      0.76       205\n",
      "\n",
      "    accuracy                           0.91       859\n",
      "   macro avg       0.95      0.81      0.85       859\n",
      "weighted avg       0.92      0.91      0.90       859\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "RandomForestClassifier()\n",
      "Train Data:\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       1.00      1.00      1.00      3052\n",
      "        Spam       1.00      1.00      1.00       957\n",
      "\n",
      "    accuracy                           1.00      4009\n",
      "   macro avg       1.00      1.00      1.00      4009\n",
      "weighted avg       1.00      1.00      1.00      4009\n",
      "\n",
      "Validation Data:\n",
      "Accuracy: 0.9837019790454016\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.98      1.00      0.99       654\n",
      "        Spam       1.00      0.93      0.96       205\n",
      "\n",
      "    accuracy                           0.98       859\n",
      "   macro avg       0.99      0.97      0.98       859\n",
      "weighted avg       0.98      0.98      0.98       859\n",
      "\n",
      "\n",
      "SVC:\n",
      "SVC(class_weight='balanced', kernel='sigmoid')\n",
      "Train Data:\n",
      "Accuracy: 0.9987528061860813\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       1.00      1.00      1.00      3052\n",
      "        Spam       0.99      1.00      1.00       957\n",
      "\n",
      "    accuracy                           1.00      4009\n",
      "   macro avg       1.00      1.00      1.00      4009\n",
      "weighted avg       1.00      1.00      1.00      4009\n",
      "\n",
      "Validation Data:\n",
      "Accuracy: 0.9918509895227008\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       1.00      0.99      0.99       654\n",
      "        Spam       0.98      0.99      0.98       205\n",
      "\n",
      "    accuracy                           0.99       859\n",
      "   macro avg       0.99      0.99      0.99       859\n",
      "weighted avg       0.99      0.99      0.99       859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_benchmark_models(val_data, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123bfd76-eb52-4d97-a858-874cdfc568c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes:\n",
      "Accuracy: 0.8883720930232558\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.87      1.00      0.93       654\n",
      "        Spam       1.00      0.53      0.70       206\n",
      "\n",
      "    accuracy                           0.89       860\n",
      "   macro avg       0.94      0.77      0.81       860\n",
      "weighted avg       0.90      0.89      0.88       860\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9825581395348837\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.98      1.00      0.99       654\n",
      "        Spam       0.98      0.94      0.96       206\n",
      "\n",
      "    accuracy                           0.98       860\n",
      "   macro avg       0.98      0.97      0.98       860\n",
      "weighted avg       0.98      0.98      0.98       860\n",
      "\n",
      "\n",
      "SVC:\n",
      "Accuracy: 0.9918604651162791\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       1.00      0.99      0.99       654\n",
      "        Spam       0.98      0.99      0.98       206\n",
      "\n",
      "    accuracy                           0.99       860\n",
      "   macro avg       0.99      0.99      0.99       860\n",
      "weighted avg       0.99      0.99      0.99       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_test_models(test_data, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df33ed-bc37-4188-a771-d6fbc84b5004",
   "metadata": {},
   "source": [
    "SVC performs best in terms of accuracy, precision, and F1-score. \n",
    "\n",
    "The Random Forest algorithm achieves a recall of 1 for Ham (i.e., there are no misclassifications of Ham as Spam), indicating that it effectively identifies legitimate messages. However, it exhibits poor recall for Spam, implying that a significant proportion of Spam messages are incorrectly classified as Ham. \n",
    "\n",
    "Therefore, if the priority is to prevent spam at all costs, the SVC model should be chosen. On the other hand, if the primary concern is to avoid misclassifying any legitimate message as spam, then the Random Forest model may be preferred."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
